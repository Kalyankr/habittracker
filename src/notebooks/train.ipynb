{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "959b9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "DATA_ROOT = Path(\"../data\")\n",
    "all_batches = []\n",
    "\n",
    "for batch_dir in sorted(DATA_ROOT.glob(\"batch_*\")):\n",
    "    data = pd.read_csv(batch_dir / \"WristMotion.csv\").sort_values(\"time\")\n",
    "    labels = pd.read_csv(batch_dir / \"Annotation.csv\").sort_values(\"time\")\n",
    "\n",
    "    data[\"batch_id\"] = batch_dir.name\n",
    "    labels[\"label\"] = labels[\"text\"].map({\"no\": 0, \"yes\": 1})\n",
    "\n",
    "    aligned = pd.merge_asof(\n",
    "        data, labels[[\"time\", \"label\"]], on=\"time\", direction=\"backward\"\n",
    "    )\n",
    "\n",
    "    aligned = aligned.dropna(subset=[\"label\"])\n",
    "    aligned[\"label\"] = aligned[\"label\"].astype(int)\n",
    "\n",
    "    all_batches.append(aligned)\n",
    "\n",
    "final_df = pd.concat(all_batches, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f4f5fd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1687, 200, 7) (1687,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "FEATURES = [\n",
    "    \"accelerationX\",\n",
    "    \"accelerationY\",\n",
    "    \"accelerationZ\",\n",
    "    \"rotationRateX\",\n",
    "    \"rotationRateY\",\n",
    "    \"rotationRateZ\",\n",
    "    \"accelerationMagnitude\",\n",
    "]\n",
    "\n",
    "WINDOW_SIZE = 200\n",
    "STEP_SIZE = 50\n",
    "\n",
    "X, y, window_batch_ids = [], [], []\n",
    "\n",
    "for batch_id, batch_df in final_df.groupby(\"batch_id\"):\n",
    "    batch_df = batch_df.reset_index(drop=True)\n",
    "\n",
    "    for start in range(0, len(batch_df) - WINDOW_SIZE, STEP_SIZE):\n",
    "        window = batch_df.iloc[start : start + WINDOW_SIZE]\n",
    "\n",
    "        label = int(window[\"label\"].mean() >= 0.5)\n",
    "\n",
    "        X.append(window[FEATURES].values)\n",
    "        y.append(label)\n",
    "        window_batch_ids.append(batch_id)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "window_batch_ids = np.array(window_batch_ids)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "\n",
    "def extract_features(X):\n",
    "    feats = []\n",
    "    for window in X:\n",
    "        mean = window.mean(axis=0)\n",
    "        std = window.std(axis=0)\n",
    "        maxv = window.max(axis=0)\n",
    "        energy = np.sum(window**2, axis=0)\n",
    "        feats.append(np.concatenate([mean, std, maxv, energy]))\n",
    "    return np.array(feats)\n",
    "\n",
    "\n",
    "X_feat = extract_features(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6712ba37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 28) (1071,)\n",
      "(616, 28) (616,)\n"
     ]
    }
   ],
   "source": [
    "test_batch = \"batch_02\"  # example\n",
    "\n",
    "train_idx = window_batch_ids != test_batch\n",
    "test_idx = window_batch_ids == test_batch\n",
    "\n",
    "X_train = X_feat[train_idx]\n",
    "y_train = y[train_idx]\n",
    "\n",
    "X_test = X_feat[test_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7a1ac55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: ['batch_01' 'batch_03' 'batch_04']\n",
      "Test batches: ['batch_02']\n"
     ]
    }
   ],
   "source": [
    "print(\"Train batches:\", np.unique(window_batch_ids[train_idx]))\n",
    "print(\"Test batches:\", np.unique(window_batch_ids[test_idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "eeed8b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       456\n",
      "           1       0.72      0.72      0.72       160\n",
      "\n",
      "    accuracy                           0.85       616\n",
      "   macro avg       0.81      0.81      0.81       616\n",
      "weighted avg       0.85      0.85      0.85       616\n",
      "\n",
      "Confusion Matrix:\n",
      "[[410  46]\n",
      " [ 44 116]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=400, max_depth=8, class_weight=\"balanced\", random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "probs = model.predict(X_test)\n",
    "THRESHOLD = 0.6  # tune this\n",
    "y_pred_raw = (probs >= THRESHOLD).astype(int)\n",
    "\n",
    "\n",
    "# Temporal smoothing (MAJOR PRECISION BOOST)\n",
    "# Majority vote over last N windows\n",
    "def smooth_predictions(preds, window=3):\n",
    "    smoothed = []\n",
    "    for i in range(len(preds)):\n",
    "        start = max(0, i - window + 1)\n",
    "        smoothed.append(int(np.mean(preds[start : i + 1]) >= 0.5))\n",
    "    return np.array(smoothed)\n",
    "\n",
    "\n",
    "y_pred = smooth_predictions(y_pred_raw, window=3)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "529ffef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerationX_mean: 0.092\n",
      "rotationRateZ_mean: 0.059\n",
      "rotationRateX_std: 0.056\n",
      "rotationRateY_std: 0.049\n",
      "accelerationZ_mean: 0.047\n",
      "accelerationY_std: 0.040\n",
      "accelerationX_std: 0.036\n",
      "accelerationZ_std: 0.034\n",
      "rotationRateZ_std: 0.029\n",
      "rotationRateX_mean: 0.018\n",
      "accelerationY_mean: 0.015\n",
      "rotationRateY_mean: 0.011\n",
      "accelerationMagnitude_mean: 0.000\n",
      "accelerationMagnitude_std: 0.000\n"
     ]
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "feature_names = [f\"{f}_mean\" for f in FEATURES] + [f\"{f}_std\" for f in FEATURES]\n",
    "\n",
    "for name, val in sorted(zip(feature_names, importances), key=lambda x: -x[1]):\n",
    "    print(f\"{name}: {val:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habittracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
